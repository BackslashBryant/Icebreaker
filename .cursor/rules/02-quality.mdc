---
description: "Quality gates and verification"
globs: ["**/*"]
alwaysApply: true
---

# Verification & Quality Gates

## Debugging & Problem-Solving Protocol

**MANDATORY**: Before fixing any bug or test failure, you MUST research the problem first:

1. **Gather Evidence**:
   - Read error messages, stack traces, and test output completely
   - Check error context files (`artifacts/test-results/*/error-context.md`)
   - Review network requests (check browser DevTools or Playwright network logs)
   - Check console logs for JavaScript errors
   - Review server logs if backend is involved
   - Take screenshots if UI-related

2. **Understand Root Cause**:
   - Identify what's actually failing (not just symptoms)
   - Check if similar issues exist in codebase
   - Review related code paths and dependencies
   - Understand expected vs actual behavior

3. **Research Solutions**:
   - Check existing tests for working patterns
   - Review documentation and code comments
   - Search codebase for similar implementations
   - Consider edge cases and error conditions

4. **Then Fix**:
   - Only after understanding root cause, implement fix
   - Test fix immediately
   - Document what was wrong and why the fix works

**NEVER**: Jump to fixes without understanding the problem first. Research → Understand → Fix.

## Dependency Import Safety

**MANDATORY**: Before committing code, validate that all imports match installed dependencies:

1. **Run dependency check**: `npm run check:dependencies`
2. **Optional dependencies**: Never use static imports - always use dynamic `import()` with try-catch
3. **Preflight validation**: Preflight automatically checks dependencies before commits

**Pattern for Optional Dependencies**:
```javascript
// ❌ BAD: Static import of optional dependency
import * as Sentry from "@sentry/node";

// ✅ GOOD: Dynamic import with fallback
let Sentry = null;
async function loadSentry() {
  if (Sentry) return Sentry;
  try {
    const sentryModule = await import("@sentry/node");
    Sentry = sentryModule.default || sentryModule;
    return Sentry;
  } catch (e) {
    console.log("[Sentry] Package not installed, skipping");
    return null;
  }
}
```

**Server Startup Validation**:
- Run `backend/tests/server-startup.test.js` to verify server can start
- E2E tests should verify server starts before running tests
- Never commit code that crashes on import if optional dependency is missing

## Automated Checks
- Prefer scripted checks whenever possible; expose them via the repository's package runner (npm/pnpm/yarn/uv/etc.) so `scripts/verify-all` can discover and execute them.
- Keep validations fast and deterministic so they can run locally and in CI.
- When adding a new stack, update `scripts/verify-all` or your package scripts to include lint, test, build, type, and audit steps appropriate to that stack.
- Run the smallest useful test suite immediately after every code change. Post the command and result in chat so reviewers can trace regressions to a single edit.
- **Testing practices**: See `.cursor/rules/08-testing.mdc` for tool selection, logging requirements, and timeout configuration.

## Manual Validation
- Document any manual verification performed (UI walkthroughs, API calls, accessibility checks).
- Capture screenshots, console output, or logs; attach them to the ticket/PR.
- Note residual risk or missing coverage so it can be automated later.
- When a loop occurs (same fix attempted twice without progress), stop, document it in `Docs/plans/Issue-<#>-plan-status-<STATUS>.md` under **Current Issues**, and reset the chat before trying again.
- **For comprehensive reviews**: Use domain team commands (`/team-testing`, `/team-security`, `/team-accessibility`, `/team-userexperience`) when multiple perspectives are needed.
- **Before release**: Use `/team-release` for final readiness check (tests, security, docs).

## CI Expectations
- `Template CI` currently runs the preflight check and best-effort verification helper.
- Extend the workflow once your stack is generated (e.g., add matrix jobs for frontend/backend services) and hook in any new verification commands you introduced.

---

# Security & Dependencies

## Safe Defaults
- Do not commit secrets, tokens, or personal data.
- Store configuration in environment variables or secret managers; document required keys in project docs.
- Review new dependencies for maintenance state, licensing, and support plans.

## Automation Aids
- Example security tooling lives in `examples/automation/`; copy only what your project needs.
- If you adopt a dependency audit or custom security script, wire it into your verify step and CI.

---

# Git Hygiene

- **BEFORE starting work**: 
  - **MANDATORY PRE-FLIGHT CHECKS** (must pass ALL):
    1. Research file exists: `docs/research/Issue-<#>-research.md`
    2. Plan-status file exists: `Docs/plans/Issue-<#>-plan-status-<STATUS>.md` with checkpoints
    3. **Team review approval file exists**: `.notes/features/<slug>/team-review-approved.md`
  - **IF ANY CHECK FAILS**: STOP immediately. Do not create, modify, or commit any files. Report which check failed and coordinate with Vector.
  - Create branch with format `agent/<agent>/<issue>-<slug>` (e.g., `agent/vector/1-onboarding-flow`) per `.cursor/rules/01-workflow.mdc`. Never work on existing branches unless they match the issue.
- **BEFORE ANY GIT OPERATION** (add, commit, push):
  - **MANDATORY GIT SAFETY CHECKS** (must pass ALL):
    1. Verify current directory is project root: Run `git rev-parse --show-toplevel` and ensure you're in that exact directory
    2. Verify current branch matches issue: Run `git branch --show-current` and confirm branch name contains the issue number
    3. Verify no parent directory scanning: `git status` should NOT show files outside the repository (no warnings about AppData, Documents, etc.)
    4. If directory is wrong: Navigate to project root with `cd "$(git rev-parse --show-toplevel)"` (PowerShell: `cd (git rev-parse --show-toplevel)`)
    5. If branch is wrong: Create correct branch or switch before committing
  - **NEVER** run git commands from parent directories or outside the repository
- One issue/task per branch; name it `agent/<agent>/<issue>-<slug>` (preferred) or `feat/<issue>-<slug>` (fallback).
- Keep commits scoped and reference the issue ID in the message: `feat: Complete Issue #X - [description]`.
- **When completing a feature** (MANDATORY workflow - NO EXCEPTIONS):
  1. Commit all changes with message referencing issue: `feat: Complete Issue #X - [description]`
  2. **MANDATORY**: Push to GitHub: `git push -u origin agent/<agent>/<issue>-<slug>` (if auth fails, use credential helper: `git config --global credential.helper manager-core`)
  3. **MANDATORY**: Update GitHub issue with completion comment (test results, verification summary, branch name, commit hash)
  4. **MANDATORY**: Update GitHub issue labels: Add `status:done`, remove `status:in-progress` (if present)
- Use `gh` CLI for branch creation, issue comments, and label updates. Terminal git is used for commits and pushes.
- Ask before committing (surface the staged diff and test results for approval), but pushing and issue updates are mandatory when completing a feature.
- Merge cleanly (squash/rebase) after quality gates are green and the ticket is updated.
- Install the provided git hook (`scripts/git-hooks/install`) so `.cursor/` changes never leave your machine unless you intentionally set `ALLOW_CURSOR_PUSH=1`.

---

# MCP Quality Checkpoints

- **UI / Accessibility**: Playwright MCP for screenshots, axe/Lighthouse when UI changes.
- **Data / Storage**: Supabase MCP for schema diffs, advisor checks, and logs.
- **Research**: DocFork MCP or Context7 for official references; summarize findings in the ticket.
- **System Ops**: Desktop Commander MCP for local shell automation when allowed.
- Always log citations in issue-specific research files (`docs/research/Issue-<#>-research.md`) when Docfork, Scout, or Vector pulls references.

Document the MCP run outputs or link to transcripts so reviewers can see what was validated.

---

# Agent Review & Diffs

- Run Cursor's **Agent Review** on every PR before handing it to humans; let it scan the diff for regressions, insecure code, or missing tests.
- Use @symbols (`@file-tree`, `@Cursor Rules`, specific filenames) to keep the agent's context precise and under token limits.
- For large/legacy codebases, break work into phases (structure/test scaffolds first, logic second) so Agent Review focuses on manageable diffs.
- Prefer using the Agent CLI/headless agents for long-running refactors or CI hooks; log their output in the issue.

---

# Lessons Learned & Rule Updates
- Treat every bug, regression, or avoided incident as an opportunity to harden the rules.
- Append concise notes to `.cursor/rules/07-process-improvement.mdc` (2-3 sentences max: trigger, lesson, rule update); when a theme recurs, evolve or add a rule file so the fix becomes default behavior.
- Keep entries brief - no verbose sections, just essential facts.
- **Date format**: **MANDATORY** - **NEVER guess dates or use placeholder dates**. Before adding ANY date to ANY file:
  1. **First**: Try Time MCP to get current date/time
  2. **If Time MCP unavailable**: Use system date command (`powershell -Command "Get-Date -Format 'yyyy-MM-dd'"` on Windows, `date +%Y-%m-%d` on Unix)
  3. **Verify**: Confirm the date is correct before using it
  4. **Never**: Use placeholder dates like "2025-01-27", "2025-01-XX", or future dates
  5. **Never**: Assume or guess the current date
  Format dates as YYYY-MM-DD. Always verify date accuracy before adding entries.

# Quality Checklist

- [ ] Preflight succeeded (run `tools/preflight.mjs` via your runtime of choice).
- [ ] Plan/tasks executed (Spec Kit or manual plan).
- [ ] Automated checks run (`scripts/verify-all` or stack-specific equivalents).
- [ ] Manual checks (if any) recorded with evidence.
- [ ] Issue/Spec updated with outcome, risk, follow-ups, and MCP recommendations.
- [ ] Git branch merged and cleaned up.
- [ ] Lessons learned documented and, if necessary, rules updated to prevent recurrence.

Anything left unchecked should be captured as follow-up work.
